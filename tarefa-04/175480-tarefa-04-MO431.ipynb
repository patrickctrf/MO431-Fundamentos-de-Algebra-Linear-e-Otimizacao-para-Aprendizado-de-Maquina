{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 04 - MO431\n",
    "\n",
    "## Patrick de Carvalho Tavares Rezende Ferreira - 175480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cma\n",
    "import hyperopt\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "from pyswarm import pso\n",
    "from scipy.optimize import dual_annealing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, ShuffleSplit\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções abaixo são auxiliares para avaliar o erro \"mean absolute error\" (MAE) em cada algoritmo que requer a chaamda de uma função para tal, obedecendo às convenções impostas por cada um para passagem dos parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna o MAE pra o SVR\n",
    "def evaluate_svr(args):\n",
    "    gamma, C, epsilon = args\n",
    "\n",
    "    gamma = 2 ** gamma\n",
    "    C = 2 ** C\n",
    "\n",
    "    svr_object = SVR(kernel='rbf', gamma=gamma, C=C, epsilon=epsilon)\n",
    "    svr_object.fit(x_treino, y_treino)\n",
    "    return mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "\n",
    "# Retorna o MAE tambem, mas recebendo argumentos como array\n",
    "def erro(x):\n",
    "    svr_object = SVR(kernel='rbf', gamma=2 ** x[0], C=2 ** x[1], epsilon=x[2])\n",
    "    svr_object.fit(x_treino, y_treino)\n",
    "    return mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "\n",
    "# Como hp nao possui distribuicoes uniformes nos expoentes de base dois, fazemos\n",
    "# este processo na funcao de avaliacao\n",
    "def evaluate_svr_hp(args):\n",
    "    gamma, C, epsilon = args\n",
    "\n",
    "    gamma = 2 ** gamma\n",
    "    C = 2 ** C\n",
    "\n",
    "    svr_object = SVR(kernel='rbf', gamma=gamma, C=C, epsilon=epsilon)\n",
    "    svr_object.fit(x_treino, y_treino)\n",
    "    return mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo, fazemos o carregamento dos dados a serem utilizados neste roteiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de treino\n",
    "x_treino = np.load(\"Xtreino5.npy\")\n",
    "y_treino = np.load(\"ytreino5.npy\")\n",
    "\n",
    "# Dados de teste\n",
    "x_teste = np.load(\"Xteste5.npy\")\n",
    "y_teste = np.load(\"yteste5.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "\n",
    "O primiro algoritmo implmentado é o random search, que amostra aleatoriamente 125 valores para os hiperparâmetros C, gamma e epsilon dentre os valores no intervalo passado para procurar a melhor combinação.\n",
    "\n",
    "Os ranges solicitados no roteiro são:\n",
    "\n",
    "* C entre $2^{-5}$ e  $2^{15}$ (uniforme nos expoentes);\n",
    "\n",
    "* Gamma entre $2^{-15}$ e  $2^3$ (uniforme nos expoentes);\n",
    "\n",
    "* Epsilon entre 0.05 a 1.0 (uniforme neste intervalo).\n",
    "\n",
    "O melhor conjunto encontrado e o MAE obtido são exibidos abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------RANDOM_SEARCH_CV---------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVR(C=11563.99742567888, cache_size=200, coef0=0.0, degree=3,\n",
      "    epsilon=0.4249541542729139, gamma=7.579089030110616e-05, kernel='rbf',\n",
      "    max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "MAE teste: \n",
      " 2.5777863091558473\n"
     ]
    }
   ],
   "source": [
    "# Fixando a semente para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.random.uniform(-5, 15, 125)\n",
    "gamma = 2 ** np.random.uniform(-15, 3, 125)\n",
    "epsilon = np.random.uniform(0.05, 1.0, 125)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c, 'gamma': gamma, 'epsilon': epsilon}\n",
    "\n",
    "svr_object = SVR()\n",
    "# Montamos o objeto que realiza a busca\n",
    "randomized_search_engine = \\\n",
    "    RandomizedSearchCV(\n",
    "        estimator=svr_object,\n",
    "        param_distributions=parametros,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=ShuffleSplit(n_splits=1)\n",
    "    )\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "randomized_search_engine.fit(x_treino, y_treino)\n",
    "\n",
    "# Predizemos os valores de teste para avaliar o resultado.\n",
    "mae = mean_absolute_error(randomized_search_engine.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\n---------------------RANDOM_SEARCH_CV---------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", randomized_search_engine.best_estimator_)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Agora implementamos o grid search, que utiliza 125 combinações de hiperparâmetros dentre as 5 opções de cada passadas como intervalo, de acordo com o solicitado no roteiro.\n",
    "\n",
    "Nota-se que o MAE obtido por este método é significativamente maior que o do random search, conforme comentado em aula. Talvez isto se deva a uma maior possibilidade de combinações para o random search, enquanto que o grid fica limitado às combinações predefinidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------GRID_SEARCH_CV---------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVR(C=0.4445411902913089, cache_size=200, coef0=0.0, degree=3,\n",
      "    epsilon=0.5259453692472857, gamma=0.0009153853954791652, kernel='rbf',\n",
      "    max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "MAE teste: \n",
      " 4.705358475374269\n"
     ]
    }
   ],
   "source": [
    "# Fixando a semente para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.random.uniform(-5, 15, 5)\n",
    "gamma = 2 ** np.random.uniform(-15, 3, 5)\n",
    "epsilon = np.random.uniform(0.05, 1.0, 5)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c, 'gamma': gamma, 'epsilon': epsilon}\n",
    "\n",
    "svr_object = SVR()\n",
    "# Montamos o objeto que realiza a busca\n",
    "randomized_search_engine = \\\n",
    "    GridSearchCV(\n",
    "        estimator=svr_object,\n",
    "        param_grid=parametros,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        cv=ShuffleSplit(n_splits=1)\n",
    "    )\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "randomized_search_engine.fit(x_treino, y_treino)\n",
    "\n",
    "# Predizemos os valores de teste para avaliar o resultado.\n",
    "mae = mean_absolute_error(randomized_search_engine.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\n---------------------GRID_SEARCH_CV---------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", randomized_search_engine.best_estimator_)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização Bayesiana\n",
    "\n",
    "Abaixo, a otimização bayesiana encontrou hiperparâmetros com valores diferentes dos anteriores e foi mais demorada também, obtendo porém um valor de MAE mais baixo que os demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:34<00:00,  3.67trial/s, best loss: 2.3462210499902336]\n",
      "\n",
      "---------------------OTIMIZAÇÃO-BAYESIANA-hyperopt---------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      "\n",
      "C:  5867.221372624267\n",
      "gamma:  4.486331407697145e-05\n",
      "epsilon:  0.095735808464466\n",
      "\n",
      "MAE teste: \n",
      " 2.3462210499902336\n"
     ]
    }
   ],
   "source": [
    "# Fixando a semente para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Definindo o espaco em que iremos trabalhar. Gamma e C serao elevados a 2\n",
    "# na funcao de avaliacao do SVR\n",
    "space = [hp.uniform('gamma', -15, 3),\n",
    "         hp.uniform('C', -5, 15),\n",
    "         hp.uniform('epsilon', 0.05, 1.0)]\n",
    "\n",
    "# calling the hyperopt function\n",
    "resultado = fmin(fn=evaluate_svr_hp, space=space, algo=tpe.suggest, max_evals=125)\n",
    "\n",
    "print(\"\\n---------------------OTIMIZAÇÃO-BAYESIANA-hyperopt---------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\")\n",
    "print(\"C: \", 2 ** resultado[\"C\"])\n",
    "\n",
    "print(\"gamma: \", 2 ** resultado[\"gamma\"])\n",
    "\n",
    "print(\"epsilon: \", resultado[\"epsilon\"])\n",
    "\n",
    "# Calculando o modelo encontrado para verificar seu erro mean_absolute_error\n",
    "svr_object = SVR(kernel='rbf', gamma=2 ** resultado[\"gamma\"], C=2 ** resultado[\"C\"], epsilon=resultado[\"epsilon\"])\n",
    "svr_object.fit(x_treino, y_treino)\n",
    "mae = mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSO\n",
    "\n",
    "Utilizando a biblioteca pyswarm, implementamos o PSO abaixo e, embora seu MAE tenha sido maior que os anteriores, ele foi bem mais rápido e utilizou apenas 11 partículas e 11 iterações. O erro MAE decresceu rapidamente quando foram utilizadas mais partículas e mais iterações, porém com tempo de execução aumentando rapidamente conforme a quantidade de iterações e partículas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping search: maximum iterations reached --> 11\n",
      "\n",
      "---------------------PSO---------------------\n",
      "\n",
      "MAE teste: \n",
      " 2.318512680271687\n",
      "C:  9699.08244654229\n",
      "epsilon:  0.29484562321646\n",
      "gamma:  3.665232614765423e-05\n"
     ]
    }
   ],
   "source": [
    "# Fixando a semente para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "lb = [-15, -5, 0.05]\n",
    "ub = [3, 15, 1.0]\n",
    "\n",
    "xopt, fopt = pso(erro, lb, ub, maxiter=11, swarmsize=11)\n",
    "\n",
    "print(\"\\n---------------------PSO---------------------\")\n",
    "\n",
    "# Calculando o modelo encontrado para verificar seu erro mean_absolute_error\n",
    "svr_object = SVR(kernel='rbf', gamma=2 ** xopt[0], C=2 ** xopt[1], epsilon=xopt[2])\n",
    "svr_object.fit(x_treino, y_treino)\n",
    "mae = mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)\n",
    "print(\"C: \", 2 ** xopt[1])\n",
    "print(\"epsilon: \", xopt[2])\n",
    "print(\"gamma: \", 2 ** xopt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Annealing\n",
    "\n",
    "Abaixo implementamos o simulated annealing através do pacote scipy.optimize.dual-annealing, que implementa o tradicional simulated annealing quando \"no_local_search=True\". A escolha deste pacote é devido à documentação mais familiar.\n",
    "\n",
    "O MAE obtido foi próximo do PSO e o tempo de execução foi de mesma ordem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------SIMULATED-ANNEALING---------------------\n",
      "\n",
      "MAE teste: \n",
      " 2.3652112209709824\n",
      "C:  4896.33391785218\n",
      "gamma:  4.7463406469492094e-05\n",
      "epsilon:  0.12451007990924375\n"
     ]
    }
   ],
   "source": [
    "# Fixando a semente para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Valores limite para a busca em cada um dos parametros\n",
    "lw = [-15, -5, 0.05]\n",
    "up = [3, 15, 1.0]\n",
    "\n",
    "resultado = dual_annealing(evaluate_svr, bounds=list(zip(lw, up)), no_local_search=True, maxiter=125)\n",
    "\n",
    "print(\"\\n---------------------SIMULATED-ANNEALING---------------------\")\n",
    "\n",
    "# Calculando o modelo encontrado para verificar seu erro mean_absolute_error\n",
    "svr_object = SVR(kernel='rbf', gamma=2 ** resultado.x[0], C=2 ** resultado.x[1], epsilon=resultado.x[2])\n",
    "svr_object.fit(x_treino, y_treino)\n",
    "mae = mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)\n",
    "\n",
    "print(\"C: \", 2 ** resultado.x[1])\n",
    "\n",
    "print(\"gamma: \", 2 ** resultado.x[0])\n",
    "\n",
    "print(\"epsilon: \", resultado.x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMA-ES\n",
    "\n",
    "Por último, fazemos a implementação do CMA-ES, que obtém erro MAE próximo ao dobro do simulated-annealing e tempo de execução parecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3_w,7)-aCMA-ES (mu_w=2.3,w_1=58%) in dimension 3 (seed=286190, Sun May 10 13:05:32 2020)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1      7 5.717387558832545e+00 1.0e+00 8.55e-02  7e-02  9e-02 0:00.1\n",
      "    2     14 5.717166328903278e+00 1.5e+00 1.10e-01  1e-01  1e-01 0:00.1\n",
      "    3     21 5.716953700733195e+00 1.6e+00 1.36e-01  1e-01  2e-01 0:00.2\n",
      "   18    126 5.568481736477731e+00 5.4e+00 7.78e-01  3e-01  2e+00 0:01.0\n",
      "termination on maxfevals=125 (Sun May 10 13:05:33 2020)\n",
      "final/bestever f-value = 5.589905e+00 5.568482e+00\n",
      "incumbent solution: [-3.7208355892031477, 0.0003926589019261906, 0.9998367455494805]\n",
      "std deviation: [1.5406137083084956, 0.6094208994881579, 0.2744027804736519]\n",
      "\n",
      "MAE teste: \n",
      " 5.5684817364777315\n",
      "C:  0.9461350310928665\n",
      "gamma:  0.06449855391549174\n",
      "epsilon:  0.9797012373039787\n"
     ]
    }
   ],
   "source": [
    "# Fixando a semente para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "opts = cma.CMAOptions()\n",
    "opts.set(\"bounds\", [[-15, -5, 0.05], [3, 15, 1.0]])\n",
    "opts.set('maxfevals', 125)\n",
    "parametros, es = cma.fmin2(evaluate_svr, [1, 1, 1], 0.1, opts)\n",
    "\n",
    "# Calculando o modelo encontrado para verificar seu erro mean_absolute_error\n",
    "svr_object = SVR(kernel='rbf', gamma=2 ** parametros[0], C=2 ** parametros[1], epsilon=parametros[2])\n",
    "svr_object.fit(x_treino, y_treino)\n",
    "mae = mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)\n",
    "\n",
    "print(\"C: \", 2 ** parametros[1])\n",
    "\n",
    "print(\"gamma: \", 2 ** parametros[0])\n",
    "\n",
    "print(\"epsilon: \", parametros[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
