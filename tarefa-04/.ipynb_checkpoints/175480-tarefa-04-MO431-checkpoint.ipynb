{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 04 - MO431\n",
    "\n",
    "## Patrick de Carvalho Tavares Rezende Ferreira - 175480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cma\n",
    "import hyperopt\n",
    "import numpy as np\n",
    "from hyperopt import fmin, tpe, hp\n",
    "\n",
    "from pyswarm import pso\n",
    "from scipy.optimize import dual_annealing\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções abaixo são auxiliares para avaliar o erro \"mean absolute error\" (MAE) em cada algoritmo que requer a chaamda de uma função para tal, obedecendo às convenções impostas por cada um para passagem dos parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna o MAE pra o SVR\n",
    "def evaluate_svr(args):\n",
    "    gamma, C, epsilon = args\n",
    "    svr_object = SVR(kernel='rbf', gamma=gamma, C=C, epsilon=epsilon)\n",
    "    svr_object.fit(x_treino, y_treino)\n",
    "    return mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "\n",
    "# Retorna o MAE tambem, mas recebendo argumentos como array\n",
    "def erro(x):\n",
    "    svr_object = SVR(kernel='rbf', gamma=x[0], C=x[1], epsilon=x[2])\n",
    "    svr_object.fit(x_treino, y_treino)\n",
    "    return mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "\n",
    "# Como hp nao possui distribuicoes uniformes nos expoentes de base dois, fazemos\n",
    "# este processo na funcao de avaliacao\n",
    "def evaluate_svr_hp(args):\n",
    "    gamma, C, epsilon = args\n",
    "\n",
    "    gamma = 2 ** gamma\n",
    "    C = 2 ** C\n",
    "\n",
    "    svr_object = SVR(kernel='rbf', gamma=gamma, C=C, epsilon=epsilon)\n",
    "    svr_object.fit(x_treino, y_treino)\n",
    "    return mean_absolute_error(svr_object.predict(x_teste), y_teste)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo, fazemos o carregamento dos dados a serem utilizados neste roteiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de treino\n",
    "x_treino = np.load(\"Xtreino5.npy\")\n",
    "y_treino = np.load(\"ytreino5.npy\")\n",
    "\n",
    "# Dados de teste\n",
    "x_teste = np.load(\"Xteste5.npy\")\n",
    "y_teste = np.load(\"yteste5.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "\n",
    "O primiro algoritmo implmentado é o random search, que amostra aleatoriamente 125 valores para os hiperparâmetros C, gamma e epsilon dentre os valores no intervalo passado para procurar a melhor combinação.\n",
    "\n",
    "Os ranges solicitados no roteiro são:\n",
    "\n",
    "* C entre $2^{-5}$ e  $2^{15}$ (uniforme nos expoentes);\n",
    "\n",
    "* Gamma entre $2^{-15}$ e  $2^3$ (uniforme nos expoentes);\n",
    "\n",
    "* Epsilon entre 0.05 a 1.0 (uniforme neste intervalo).\n",
    "\n",
    "O melhor conjunto encontrado e o MAE obtido são exibidos abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/home/patrick/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------RANDOM_SEARCH_CV---------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVR(C=11563.99742567888, cache_size=200, coef0=0.0, degree=3,\n",
      "    epsilon=0.4249541542729139, gamma=7.579089030110616e-05, kernel='rbf',\n",
      "    max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "MAE teste: \n",
      " 2.5777863091558473\n"
     ]
    }
   ],
   "source": [
    "# Fixando a semente para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.random.uniform(-5, 15, 125)\n",
    "gamma = 2 ** np.random.uniform(-15, 3, 125)\n",
    "epsilon = np.random.uniform(0.05, 1.0, 125)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c, 'gamma': gamma, 'epsilon': epsilon}\n",
    "\n",
    "svr_object = SVR()\n",
    "# Montamos o objeto que realiza a busca\n",
    "randomized_search_engine = \\\n",
    "    RandomizedSearchCV(\n",
    "        estimator=svr_object,\n",
    "        param_distributions=parametros,\n",
    "        scoring=\"neg_mean_absolute_error\"\n",
    "    )\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "randomized_search_engine.fit(x_treino, y_treino)\n",
    "\n",
    "# Predizemos os valores de teste para avaliar o resultado.\n",
    "mae = mean_absolute_error(randomized_search_engine.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\n---------------------RANDOM_SEARCH_CV---------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", randomized_search_engine.best_estimator_)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "\n",
    "Agora implementamos o grid search, que utiliza 125 combinações de hiperparâmetros dentre as 5 opções de cada passadas como intervalo, de acordo com o solicitado no roteiro.\n",
    "\n",
    "Nota-se que o MAE obtido por este método é significativamente maior que o do random search, conforme comentado em aula. Talvez isto se deva a uma maior possibilidade de combinações para o random search, enquanto que o grid fica limitado às combinações predefinidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------GRID_SEARCH_CV---------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      " SVR(C=173.90738895885403, cache_size=200, coef0=0.0, degree=3,\n",
      "    epsilon=0.5259453692472857, gamma=0.0009153853954791652, kernel='rbf',\n",
      "    max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      "\n",
      "MAE teste: \n",
      " 3.513009649620907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fixando a emenete para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Gera os parametros de entrada aleatoriamente. Alguns sao uniformes nos\n",
    "# EXPOENTES.\n",
    "c = 2 ** np.random.uniform(-5, 15, 5)\n",
    "gamma = 2 ** np.random.uniform(-15, 3, 5)\n",
    "epsilon = np.random.uniform(0.05, 1.0, 5)\n",
    "\n",
    "# Une os parametros de entrada em um unico dicionario a ser passado para a\n",
    "# funcao.\n",
    "parametros = {'C': c, 'gamma': gamma, 'epsilon': epsilon}\n",
    "\n",
    "svr_object = SVR()\n",
    "# Montamos o objeto que realiza a busca\n",
    "randomized_search_engine = \\\n",
    "    GridSearchCV(\n",
    "        estimator=svr_object,\n",
    "        param_grid=parametros,\n",
    "        scoring=\"neg_mean_absolute_error\"\n",
    "    )\n",
    "\n",
    "# Realizamos a busca atraves do treinamento\n",
    "randomized_search_engine.fit(x_treino, y_treino)\n",
    "\n",
    "# Predizemos os valores de teste para avaliar o resultado.\n",
    "mae = mean_absolute_error(randomized_search_engine.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\n---------------------GRID_SEARCH_CV---------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\", randomized_search_engine.best_estimator_)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização Bayesiana\n",
    "\n",
    "Abaixo, a otimização bayesiana encontrou hiperparâmetros com valores diferentes dos anteriores e foi mais demorada também, obtendo porém um valor de MAE mais baixo que os demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:39<00:00,  3.16trial/s, best loss: 2.334475448042146]\n",
      "\n",
      "---------------------OTIMIZAÇÃO-BAYESIANA-hyperopt---------------------\n",
      "\n",
      "Melhor conjunto de parâmetros: \n",
      "\n",
      "C:  6533.445136525573\n",
      "gamma:  4.437629996505538e-05\n",
      "epsilon:  0.20125506546303307\n",
      "\n",
      "MAE teste: \n",
      " 2.334475448042146\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fixando a semente para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Definindo o espaco em que iremos trabalhar. Gamma e C serao elevados a 2\n",
    "# na funcao de avaliacao do SVR\n",
    "space = [hp.uniform('gamma', -15, 3),\n",
    "         hp.uniform('C', -5, 15),\n",
    "         hp.uniform('epsilon', 0.05, 1.0)]\n",
    "\n",
    "# calling the hyperopt function\n",
    "resultado = fmin(fn=evaluate_svr_hp, space=space, algo=tpe.suggest, max_evals=125)\n",
    "\n",
    "print(\"\\n---------------------OTIMIZAÇÃO-BAYESIANA-hyperopt---------------------\")\n",
    "\n",
    "print(\"\\nMelhor conjunto de parâmetros: \\n\")\n",
    "print(\"C: \", 2 ** resultado[\"C\"])\n",
    "\n",
    "print(\"gamma: \", 2 ** resultado[\"gamma\"])\n",
    "\n",
    "print(\"epsilon: \", resultado[\"epsilon\"])\n",
    "\n",
    "# Calculando o modelo encontrado para verificar seu erro mean_absolute_error\n",
    "svr_object = SVR(kernel='rbf', gamma=2 ** resultado[\"gamma\"], C=2 ** resultado[\"C\"], epsilon=resultado[\"epsilon\"])\n",
    "svr_object.fit(x_treino, y_treino)\n",
    "mae = mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSO\n",
    "\n",
    "Utilizando a biblioteca pyswarm, implementamos o PSO abaixo e, embora seu MAE tenha sido maior que os anteriores, ele foi bem mais rápido e utilizou apenas 11 partículas e 11 iterações. O erro MAE decresceu rapidamente quando foram utilizadas mais partículas e mais iterações, com tempo próximo ao otimizaor bayesiano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixando a semente para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "lb = [2 ** (-15), 2 ** (-5), 0.05]\n",
    "ub = [2 ** 3, 2 ** 15, 1.0]\n",
    "\n",
    "xopt, fopt = pso(erro, lb, ub, maxiter=11, swarmsize=11)\n",
    "\n",
    "print(\"\\n---------------------PSO---------------------\")\n",
    "\n",
    "# Calculando o modelo encontrado para verificar seu erro mean_absolute_error\n",
    "svr_object = SVR(kernel='rbf', gamma=xopt[0], C=xopt[1], epsilon=xopt[2])\n",
    "svr_object.fit(x_treino, y_treino)\n",
    "mae = mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)\n",
    "print(\"C: \", xopt[1])\n",
    "print(\"epsilon: \", xopt[2])\n",
    "print(\"gamma: \", xopt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Annealing\n",
    "\n",
    "Abaixo implementamos o simulated annealing através do pacote scipy.optimize.dual-annealing, que implementa o tradicional simulated annealing quando \"no_local_search=True\". A escolha deste pacote é devido à documentação mais familiar.\n",
    "\n",
    "O MAE obtido foi próximo ao do PSO e o tempo de execução foi de mesma ordem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------SIMULATED-ANNEALING---------------------\n",
      "\n",
      "MAE teste: \n",
      " 4.029688851184638\n",
      "C:  1929.20961345861\n",
      "gamma:  0.020801800378464463\n",
      "epsilon:  0.05253698470615205\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fixando a semente para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Valores limite para a busca em cada um dos parametros\n",
    "lw = [2 ** (-15), 2 ** (-5), 0.05]\n",
    "up = [2 ** 3, 2 ** (15), 1.0]\n",
    "\n",
    "# Valores iniciais para a busca\n",
    "values = [1, 1, 1]\n",
    "\n",
    "resultado = dual_annealing(evaluate_svr, bounds=list(zip(lw, up)), no_local_search=True, maxiter=125)\n",
    "\n",
    "print(\"\\n---------------------SIMULATED-ANNEALING---------------------\")\n",
    "\n",
    "# Calculando o modelo encontrado para verificar seu erro mean_absolute_error\n",
    "svr_object = SVR(kernel='rbf', gamma=resultado.x[0], C=resultado.x[1], epsilon=resultado.x[2])\n",
    "svr_object.fit(x_treino, y_treino)\n",
    "mae = mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)\n",
    "\n",
    "print(\"C: \", resultado.x[1])\n",
    "\n",
    "print(\"gamma: \", resultado.x[0])\n",
    "\n",
    "print(\"epsilon: \", resultado.x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CMA-ES\n",
    "\n",
    "Por último, fazemos a implementação do CMA-ES, que obtém erro MAE próximo ao do simulated-annealing e tempo de execução parecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3_w,7)-aCMA-ES (mu_w=2.3,w_1=58%) in dimension 3 (seed=996153, Wed May  6 21:17:08 2020)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1      7 5.715471718601445e+00 1.0e+00 1.26e-01  1e-01  2e-01 0:00.1\n",
      "    2     14 5.713633801003319e+00 1.4e+00 1.91e-01  2e-01  3e-01 0:00.2\n",
      "    3     21 5.596149477249732e+00 1.7e+00 3.33e-01  3e-01  4e-01 0:00.2\n",
      "   18    126 4.189937600167210e+00 7.1e+00 1.46e-01  3e-02  2e-01 0:01.7\n",
      "termination on maxfevals=125 (Wed May  6 21:17:10 2020)\n",
      "final/bestever f-value = 4.272895e+00 4.111240e+00\n",
      "incumbent solution: [0.0021502272709660306, 1.3317661394386389, 0.4660763418008175]\n",
      "std deviation: [0.029368342426706637, 0.1494172454441973, 0.15822134701499527]\n",
      "\n",
      "---------------------CMA-ES---------------------\n",
      "\n",
      "MAE teste: \n",
      " 4.111239679240198\n",
      "C:  1.4690056867904175\n",
      "gamma:  0.000611884606878545\n",
      "epsilon:  0.4195338006316037\n"
     ]
    }
   ],
   "source": [
    "# Fixando a semente para garantir resultados aleatorios reprodutiveis.\n",
    "np.random.seed(1234)\n",
    "\n",
    "opts = cma.CMAOptions()\n",
    "opts.set(\"bounds\", [[2 ** (-15), 2 ** (-5), 0.05], [2 ** 3, 2 ** (15), 1.0]])\n",
    "opts.set('maxfevals', 125)\n",
    "parametros, es = cma.fmin2(evaluate_svr, [1, 1, 1], 0.1, opts)\n",
    "\n",
    "print(\"\\n---------------------CMA-ES---------------------\")\n",
    "\n",
    "# Calculando o modelo encontrado para verificar seu erro mean_absolute_error\n",
    "svr_object = SVR(kernel='rbf', gamma=parametros[0], C=parametros[1], epsilon=parametros[2])\n",
    "svr_object.fit(x_treino, y_treino)\n",
    "mae = mean_absolute_error(svr_object.predict(x_teste), y_teste)\n",
    "\n",
    "print(\"\\nMAE teste: \\n\", mae)\n",
    "\n",
    "print(\"C: \", parametros[1])\n",
    "\n",
    "print(\"gamma: \", parametros[0])\n",
    "\n",
    "print(\"epsilon: \", parametros[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
